# -*- coding: utf-8 -*-
"""HiLLoC RVAE Compression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11967hjFQczjW21cLLTFhOnTurx3mSBVD
"""
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"

from torch.utils.data import DataLoader
from config import Config_hilloc
from utils.common import load_data, same_seed

import numpy as onp
params = onp.load('./model/params/hilloc_official_pt.npy', allow_pickle=True).item()

cf = Config_hilloc()
cf_compress = cf.compress_hparam
cf_model = cf.model_hparam

same_seed(cf.seed)

if cf_compress.general_test:
    dataset = cf_compress.general_test_dataset
else:
    dataset = cf.dataset
batch_size = cf_compress.batch_size

print(f"Model:{cf.model_name}; Dataset:{dataset}")

_, test_set = load_data(dataset, cf.model_name, load_train=False)
test_loader = DataLoader(
    dataset=test_set, sampler=None, 
    batch_size=batch_size, shuffle=True)

num_images = 10000#len(test_set)
images = []
for i, x in enumerate(test_loader):
    if i == num_images:
        break
    images.append(onp.transpose(x[0].numpy().astype(onp.uint64), (0, 2, 3, 1)))

xdim = images[0].shape[1:]
n_batches = len(images) // batch_size
num_dims = len(images) * onp.prod(xdim)
print(f'num data: {len(images)} x {images[0].shape}')

def get_params(name, layer=None):
  """Interface for the dict of tensorflow params"""
  if layer is not None:
    s = 'model/IAF_0_{}/{}/'.format(layer, name)
  else:
    s = 'model/{}/'.format(name)
  W = params[s+'V:0']
  g = params[s+'g:0']
  b = params[s+'b:0']
  return W, g, b

import jax.numpy as np
from jax import lax, random, jit, nn
from jax.scipy.stats import norm
from jax.nn.initializers import glorot_normal, normal, ones
import craystack as cs
import itertools
from functools import partial
from autograd.builtins import tuple as ag_tuple


z_size = 32
h_size = 160
depth = 24

dimension_numbers = ('NHWC', 'HWIO', 'NHWC')
one = (1, 1)

conv = partial(lax.conv_general_dilated, 
               dimension_numbers=dimension_numbers, 
               padding='SAME')

def l2_normalize(x, axis, epsilon=1e-12):
  l2 = np.sum(np.square(x), axis=axis, keepdims=True)
  l2 = np.sqrt(np.maximum(l2, epsilon))
  return x / l2

def apply_conv(params, inputs, strides=one):
    W, g, b = params
    W = np.exp(g) * l2_normalize(W, axis=[0, 1, 2])  # weight norm
    return conv(inputs, W, strides) + b

def empty_list(l):
  return [None for i in range(l)]

def get_params(name, layer=None):
  if layer is not None:
    s = 'model/IAF_0_{}/{}/'.format(layer, name)
  else:
    s = 'model/{}/'.format(name)
  W = params[s+'V:0']
  g = params[s+'g:0']
  b = params[s+'b:0']
  return W, g, b


## ------------------------- MODEL ---------------------------------

def down_split(layer, inputs):
  out = nn.elu(inputs)
  out = apply_conv(get_params('down_conv1', layer), out)
  prior_mean, prior_logstd, rz_mean, rz_logstd, _, h_det = \
    np.split(out, [z_size, 2*z_size, 3*z_size, 4*z_size, 
                   4*z_size + h_size], axis=-1)
  return (prior_mean, prior_logstd, rz_mean, rz_logstd), h_det

def down_merge(layer, h_det, inputs, z):
  h = np.concatenate([z, h_det], axis=-1)
  h = nn.elu(h)
  h = apply_conv(get_params('down_conv2', layer), h)
  inputs = inputs + 0.1 * h
  return inputs

def up_pass(x):
  inputs = np.clip((x.astype('float64') + 0.5) / 256.0, 0.0, 1.0) - 0.5
  inputs = apply_conv(get_params('x_enc'), inputs, strides=(2, 2))

  q_stats = empty_list(depth)  # these are all we care about from the up pass  
  for i in range(depth):
    # up split
    out = nn.elu(inputs)
    out = apply_conv(get_params('up_conv1', i), out)
    qz_mean, qz_logstd, _, h = np.split(out, [z_size, 2*z_size, 2*z_size + h_size], axis=-1)                
    q_stats[i] = qz_mean, qz_logstd

    # up merge
    h = nn.elu(h)
    h = apply_conv(get_params('up_conv3', i), h)
    inputs =  inputs + 0.1 * h
  return q_stats

def upsample_and_postprocess(inputs):
  out = nn.elu(inputs)
  W, g, b = get_params('x_dec')
  # W is HWOI rather than HWIO, and gets normalised incorrectly it seems
  W = np.exp(g).reshape(1, 1, -1, 1) * l2_normalize(W, axis=(0, 1, 2))
  # transpose_kernel for compatibility with tf conv transpose
  out = lax.conv_transpose(out, W, dimension_numbers=('NHWC', 'HWIO', 'NHWC'),
                           strides=(2, 2), padding='SAME', 
                           transpose_kernel=True)
  out += b
  return np.clip(out, -0.5 + 1 / 512., 0.5 - 1 / 512.)

def rvae_codec(x_precision, prior_prec, posterior_prec, data_shape):
  batch_size, h, w, c = data_shape
  z_view = lambda head: head[0]
  x_view = lambda head: head[1]

  x_logstd = params['model/dec_log_stdv:0']
  h_init = params['model/h_top:0']

  prior_codec = cs.substack(cs.Uniform(prior_prec), z_view)
  def post_codec(post_mean, post_stdd, prior_mean, prior_stdd):
    return cs.substack(cs.DiagGaussian_GaussianBins(post_mean, post_stdd,
      prior_mean, prior_stdd, posterior_prec, prior_prec), z_view)
  def x_codec(x_mean):
    return cs.substack(
        cs.Logistic_UnifBins(x_mean, x_logstd, x_precision, 
                             bin_prec=8, bin_lb=-0.5, bin_ub=0.5), x_view)

  def push(message, data):
    q_stats = up_pass(data)

    # run down pass and pop according to posterior, top down
    inputs = np.tile(np.reshape(h_init, (1, 1, 1, -1)), 
                     (1, h//2, w//2, 1))  # assuming batch size 1 for now
    zs = empty_list(depth)
    for i in reversed(range(depth)):
      (prior_mean, prior_logstd, rz_mean, rz_logstd), h_det = \
        down_split(i, inputs)
      qz_mean, qz_logstd = q_stats[i]

      codec = post_codec(qz_mean + rz_mean, np.exp(qz_logstd + rz_logstd),
                         prior_mean, np.exp(prior_logstd))
      message, z = codec.pop(message)
      zs[i] = z
      z = prior_mean + \
        cs.std_gaussian_centres(prior_prec)[z] * np.exp(prior_logstd)
      inputs = down_merge(i, h_det, inputs, z)
    
    # push data
    x_mean = upsample_and_postprocess(inputs)
    codec = x_codec(x_mean)
    message, = codec.push(message, data)

    # push z according to prior, bottom up
    for i in range(depth):
      message, = prior_codec.push(message, zs[i])
    return message,

  def pop(message):
    # pop z according to prior, top down
    zs = empty_list(depth)
    rp_stats = empty_list(depth)
    inputs = np.tile(np.reshape(h_init, (1, 1, 1, -1)), 
                     (1, h//2, w//2, 1))  # assuming batch size 1
    for i in reversed(range(depth)):
      message, z = prior_codec.pop(message)
      (prior_mean, prior_logstd, rz_mean, rz_logstd), h_det =  \
        down_split(i, inputs)
      zs[i] = z
      rp_stats[i] = prior_mean, prior_logstd, rz_mean, rz_logstd
      z = prior_mean + \
        cs.std_gaussian_centres(prior_prec)[z] * np.exp(prior_logstd)
      inputs = down_merge(i, h_det, inputs, z)
      
    # pop data
    x_mean = upsample_and_postprocess(inputs)
    codec = x_codec(x_mean)
    message, data = codec.pop(message)

    # push z according to posterior, bottom up
    q_stats = up_pass(data)
    for i in range(depth):
      qz_mean, qz_logstd = q_stats[i]
      prior_mean, prior_logstd, rz_mean, rz_logstd = rp_stats[i]
      codec = post_codec(qz_mean + rz_mean, np.exp(qz_logstd + rz_logstd),
                         prior_mean, np.exp(prior_logstd))
      message, = codec.push(message, zs[i])
    return message, data
  return cs.Codec(push, pop)

## ---------------------- COMPRESSION ----------------------------
prior_precision = 10
x_precision = 24
q_precision = 18
l1 = 1000000

import os
import pickle
state_path = f"bitstreams/initial_bit_{l1}.pkl"
if os.path.exists(state_path):
    print('load init state')
    with open(state_path, 'rb') as f:
        state = pickle.load(f)
else:
    print('create init state')
    state = cs.random_message(cf_compress.initial_bits, (1,))
    with open(state_path, 'wb') as f:
        pickle.dump(state, f)

x_shape = images[0].shape  # expect image to be NHWC
latent_shape = (x_shape[0], x_shape[1]//2, x_shape[2]//2, 32)
latent_size = onp.prod(latent_shape)
def vae_view(head):
  return ag_tuple((onp.reshape(head[:latent_size], latent_shape),
                   onp.reshape(head[latent_size:], x_shape)))
codec = cs.substack(rvae_codec(x_precision, prior_precision, 
                               q_precision, x_shape), 
                    vae_view)

# rng = onp.random.RandomState(0)
# message = cs.random_message(l1, (onp.prod(x_shape) + latent_size,), rng)
# init_state = cs.flatten(message)
init_state = cs.flatten(state)
message = cs.reshape_head(state, (onp.prod(x_shape) + latent_size,))

for i, x in enumerate(images):
  message, = codec.push(message, x)

flat_state = cs.flatten(message)
l2 = len(cs.flatten(message))

count = 0
for i in range(1, len(init_state)):
    if init_state[-i] == flat_state[-i]:
        count += 1
    else:
        break
init_cost = 32 * (len(init_state) - count)
print(f'Initial cost: {init_cost} bits.')

total_bits = 32 * (l2 - l1) + init_cost
print("Total used {} bits.".format(total_bits))
print("Bit rate: {:.4f} bits per dim.".format(total_bits / num_dims))

print('Net bit rate: {:.4f} bits per dim.'.format(32 * (l2 - l1) / num_dims))
# message_, image_ = codec.pop(message)
# onp.testing.assert_equal(image, image_)
# onp.testing.assert_equal(init_state, cs.flatten(message_))